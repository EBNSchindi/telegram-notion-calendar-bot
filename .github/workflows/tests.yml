name: Test Suite

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    # Run tests daily at 2 AM UTC
    - cron: '0 2 * * *'

env:
  PYTHON_VERSION: '3.11'
  TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN_TEST }}
  NOTION_API_KEY: ${{ secrets.NOTION_API_KEY_TEST }}
  NOTION_DATABASE_ID: ${{ secrets.NOTION_DATABASE_ID_TEST }}
  OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY_TEST }}

jobs:
  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Cache dependencies
      uses: actions/cache@v3
      with:
        path: |
          ~/.cache/pip
          venv
        key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Run unit tests
      run: |
        pytest tests/test_handlers/ tests/test_services/ tests/test_models/ tests/test_utils/ \
          -v -m unit \
          --cov=src \
          --cov-report=xml \
          --cov-report=html \
          --junit-xml=test-results/unit-tests.xml
    
    - name: Upload coverage
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: unit
        name: unit-coverage
    
    - name: Upload test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: unit-test-results
        path: test-results/

  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: unit-tests
    
    services:
      postgres:
        image: postgres:14
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Run integration tests
      env:
        DATABASE_URL: postgresql://postgres:postgres@localhost:5432/test_db
      run: |
        pytest tests/test_integration/ \
          -v -m integration \
          --cov=src \
          --cov-report=xml \
          --junit-xml=test-results/integration-tests.xml
    
    - name: Upload coverage
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: integration
        name: integration-coverage

  e2e-tests:
    name: End-to-End Tests
    runs-on: ubuntu-latest
    needs: integration-tests
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Start bot in test mode
      run: |
        python src/bot.py --test-mode &
        BOT_PID=$!
        echo "BOT_PID=$BOT_PID" >> $GITHUB_ENV
        sleep 5  # Wait for bot to start
    
    - name: Run E2E tests
      run: |
        pytest tests/test_e2e/ \
          -v -m e2e \
          --junit-xml=test-results/e2e-tests.xml
    
    - name: Stop bot
      if: always()
      run: |
        if [ ! -z "$BOT_PID" ]; then
          kill $BOT_PID || true
        fi

  performance-tests:
    name: Performance Tests
    runs-on: ubuntu-latest
    needs: unit-tests
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Run performance tests
      run: |
        pytest tests/test_performance/ \
          -v -m performance \
          --benchmark-only \
          --benchmark-autosave \
          --junit-xml=test-results/performance-tests.xml
    
    - name: Upload benchmark results
      uses: actions/upload-artifact@v3
      with:
        name: benchmark-results
        path: .benchmarks/

  security-tests:
    name: Security Tests
    runs-on: ubuntu-latest
    needs: unit-tests
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install bandit safety
    
    - name: Run security tests
      run: |
        pytest tests/test_security/ \
          -v -m security \
          --junit-xml=test-results/security-tests.xml
    
    - name: Run Bandit security scan
      run: |
        bandit -r src/ -f json -o bandit-report.json || true
    
    - name: Run Safety check
      run: |
        safety check --json --output safety-report.json || true
    
    - name: Upload security reports
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: security-reports
        path: |
          bandit-report.json
          safety-report.json

  load-tests:
    name: Load Tests
    runs-on: ubuntu-latest
    needs: [integration-tests, e2e-tests]
    if: github.event_name == 'schedule' || github.event_name == 'workflow_dispatch'
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Run load tests
      run: |
        cd tests/test_load
        ./run_load_tests.sh
      env:
        TEST_TYPE: headless
        USERS: 50
        RUN_TIME: 2m
    
    - name: Upload load test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: load-test-results
        path: tests/test_load/results/

  test-coverage-check:
    name: Test Coverage Check
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests]
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Generate coverage report
      run: |
        pytest tests/ \
          --cov=src \
          --cov-report=term-missing \
          --cov-report=html \
          --cov-fail-under=80
    
    - name: Upload coverage HTML report
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: coverage-report
        path: htmlcov/
    
    - name: Comment PR with coverage
      uses: py-cov-action/python-coverage-comment-action@v3
      if: github.event_name == 'pull_request'
      with:
        GITHUB_TOKEN: ${{ github.token }}

  all-tests-passed:
    name: All Tests Passed
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests, e2e-tests, performance-tests, security-tests, test-coverage-check]
    
    steps:
    - name: Tests Summary
      run: |
        echo "✅ All tests passed successfully!"
        echo "- Unit Tests: ✓"
        echo "- Integration Tests: ✓"
        echo "- E2E Tests: ✓"
        echo "- Performance Tests: ✓"
        echo "- Security Tests: ✓"
        echo "- Coverage Check: ✓"